{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40abc755-f617-4d5d-a521-41eb32478a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# ========== 数据读取 ==========\n",
    "main_data_path = r\"D:\\ML-3DPrinting-Project\\data\\7.7\\2_regression_original.xlsx\"\n",
    "smiles_path = r\"D:\\\\ML-3DPrinting-Project\\\\data\\\\smiles.xlsx\"\n",
    "df_main = pd.read_excel(main_data_path)\n",
    "df_smiles = pd.read_excel(smiles_path)\n",
    "\n",
    "# ===== 第一步：提取 API 名称 =====\n",
    "api_names = df_smiles[df_smiles[\"is_API\"] == 1][\"material_name\"].tolist()\n",
    "excipient_names = df_smiles[df_smiles[\"is_API\"] == 0][\"material_name\"].tolist()\n",
    "api_names = [col for col in api_names if col in df_main.columns]\n",
    "excipient_names = [col for col in excipient_names if col in df_main.columns]\n",
    "\n",
    "# ===== 第二步：构造主 API 列 =====\n",
    "api_dose_df = df_main[api_names].copy()\n",
    "api_dose_df[\"API_name\"] = api_dose_df.apply(\n",
    "    lambda row: row[row > 0].index[0] if any(row > 0) else \"Unknown\", axis=1\n",
    ")\n",
    "\n",
    "# ===== 第三步：构造 API_dose 列 =====\n",
    "api_dose_df[\"API_dose\"] = [\n",
    "    row[api] if api in row else 0\n",
    "    for row, api in zip(api_dose_df[api_names].to_dict(orient=\"records\"), api_dose_df[\"API_name\"])\n",
    "]\n",
    "\n",
    "# ===== 第四步：构造过滤条件（统一过滤）=====\n",
    "valid_mask = (\n",
    "    (api_dose_df[\"API_name\"] != \"Unknown\") &\n",
    "    (df_main[\"printability\"].isin([\"yes\", \"no\"]))\n",
    ")\n",
    "\n",
    "# ===== 第五步：过滤所有相关数据 =====\n",
    "df_main = df_main[valid_mask].copy()\n",
    "api_dose_df = api_dose_df[valid_mask].copy()\n",
    "\n",
    "X = df_main[excipient_names].fillna(0).values  # ✅ filtered!\n",
    "\n",
    "\n",
    "# ===== 第六步：API名称独热编码 + 用量向量 =====\n",
    "api_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "api_onehot = api_encoder.fit_transform(api_dose_df[[\"API_name\"]])\n",
    "api_dose_vector = np.array(api_dose_df[\"API_dose\"].fillna(0)).reshape(-1, 1)\n",
    "\n",
    "# ===== 第七步：处理标签并构造最终训练输入 =====\n",
    "printability = df_main[\"printability\"].map({\"yes\": 1, \"no\": 0}).values.reshape(-1, 1)\n",
    "cond = np.hstack([api_onehot, api_dose_vector, printability])\n",
    "assert X.shape[0] == cond.shape[0], \"❌ X 与 cond 样本数不一致！\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a17fe08b-a4ff-4522-8feb-98e432ddb34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 2. Dataset + mask ==========\n",
    "def mask_x(x, mask_prob=0.3):\n",
    "    mask = torch.bernoulli(torch.ones_like(x) * (1 - mask_prob))\n",
    "    return x * mask\n",
    "\n",
    "class FormulationDataset(Dataset):\n",
    "    def __init__(self, X, cond):\n",
    "        self.x = torch.FloatTensor(X)\n",
    "        self.cond = torch.FloatTensor(cond)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"x\": self.x[idx], \"cond\": self.cond[idx]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4e5b88-0021-4c1e-ae54-553abfd5626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 3. Conditional VAE ==========\n",
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, input_dim, cond_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim + cond_dim, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 128), nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(128, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128, latent_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim + cond_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 256), nn.ReLU(),\n",
    "            nn.Linear(256, input_dim), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x, cond):\n",
    "        h = self.encoder(torch.cat([x, cond], dim=1))\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, cond):\n",
    "        return self.decoder(torch.cat([z, cond], dim=1))\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        mu, logvar = self.encode(x, cond)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z, cond), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719056c9-7c89-40b0-943a-c25a76cba03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 4. Loss ==========\n",
    "def vae_loss(recon_x, x_true, mu, logvar):\n",
    "    mse = F.mse_loss(recon_x, x_true, reduction='sum')  # 预测excipient用量\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return mse + kld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7839301-fe84-4dd8-a8ae-ae07a2061cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1116, 269), cond shape: (1116, 57)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}, cond shape: {cond.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f05b7a3-260a-4431-985b-a45b05dd367e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 46443.98\n",
      "Epoch 2/50, Loss: 2242.57\n",
      "Epoch 3/50, Loss: 633.04\n",
      "Epoch 4/50, Loss: 558.32\n",
      "Epoch 5/50, Loss: 530.29\n",
      "Epoch 6/50, Loss: 521.67\n",
      "Epoch 7/50, Loss: 518.05\n",
      "Epoch 8/50, Loss: 518.26\n",
      "Epoch 9/50, Loss: 514.94\n",
      "Epoch 10/50, Loss: 513.17\n",
      "Epoch 11/50, Loss: 512.05\n",
      "Epoch 12/50, Loss: 510.77\n",
      "Epoch 13/50, Loss: 510.47\n",
      "Epoch 14/50, Loss: 510.08\n",
      "Epoch 15/50, Loss: 508.83\n",
      "Epoch 16/50, Loss: 507.71\n",
      "Epoch 17/50, Loss: 507.93\n",
      "Epoch 18/50, Loss: 507.98\n",
      "Epoch 19/50, Loss: 506.89\n",
      "Epoch 20/50, Loss: 506.74\n",
      "Epoch 21/50, Loss: 506.39\n",
      "Epoch 22/50, Loss: 507.06\n",
      "Epoch 23/50, Loss: 505.59\n",
      "Epoch 24/50, Loss: 506.43\n",
      "Epoch 25/50, Loss: 505.64\n",
      "Epoch 26/50, Loss: 505.20\n",
      "Epoch 27/50, Loss: 504.72\n",
      "Epoch 28/50, Loss: 504.74\n",
      "Epoch 29/50, Loss: 504.90\n",
      "Epoch 30/50, Loss: 505.11\n",
      "Epoch 31/50, Loss: 504.31\n",
      "Epoch 32/50, Loss: 503.91\n",
      "Epoch 33/50, Loss: 504.20\n",
      "Epoch 34/50, Loss: 504.69\n",
      "Epoch 35/50, Loss: 504.08\n",
      "Epoch 36/50, Loss: 504.41\n",
      "Epoch 37/50, Loss: 503.89\n",
      "Epoch 38/50, Loss: 503.39\n",
      "Epoch 39/50, Loss: 503.75\n",
      "Epoch 40/50, Loss: 503.69\n",
      "Epoch 41/50, Loss: 503.33\n",
      "Epoch 42/50, Loss: 503.47\n",
      "Epoch 43/50, Loss: 503.16\n",
      "Epoch 44/50, Loss: 502.75\n",
      "Epoch 45/50, Loss: 503.16\n",
      "Epoch 46/50, Loss: 502.55\n",
      "Epoch 47/50, Loss: 502.79\n",
      "Epoch 48/50, Loss: 502.50\n",
      "Epoch 49/50, Loss: 502.00\n",
      "Epoch 50/50, Loss: 502.64\n"
     ]
    }
   ],
   "source": [
    "# ========== 5. Train ==========\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LATENT_DIM = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "dataset = FormulationDataset(X, cond)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = ConditionalVAE(input_dim=X.shape[1], cond_dim=cond.shape[1], latent_dim=LATENT_DIM)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x = mask_x(batch['x'])\n",
    "        cond_batch = batch['cond']\n",
    "        recon, mu, logvar = model(x, cond_batch)\n",
    "        loss = vae_loss(recon, batch['x'], mu, logvar)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da00dcf5-8bd9-487c-b818-b87c712eb312",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_dosed_formulation(model, cond_vector):\n",
    "    model.eval()\n",
    "    cond_tensor = torch.FloatTensor(cond_vector).unsqueeze(0)\n",
    "    z = torch.randn(1, model.fc_mu.out_features)\n",
    "    output = model.decode(z, cond_tensor).squeeze().numpy()\n",
    "    return output  # 直接返回每个 excipient 的预测用量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86539f6-ce28-41c3-bfb3-e3d37165b87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推荐配方及用量：\n",
      "Mannitol: 0.06400000303983688\n",
      "HydroxypropylcelluloseKlucelEF: 0.032999999821186066\n",
      "PolyvinylalcoholPVAfilament: 0.032999999821186066\n",
      "PolyvinylalcoholParteckMXP: 0.03200000151991844\n",
      "HydroxypropylmethylcelluloseAffinisol15LV: 0.02500000037252903\n"
     ]
    }
   ],
   "source": [
    "# ========== 7. 示例: 按照 API + 剂量 + printability 生成配方 ==========\n",
    "new_cond = np.zeros(cond.shape[1])\n",
    "new_cond[api_encoder.categories_[0].tolist().index(\"Paracetamol\")] = 1\n",
    "new_cond[-2] = 0.65  # dose\n",
    "new_cond[-1] = 1     # printable\n",
    "\n",
    "output = generate_dosed_formulation(model, new_cond)\n",
    "\n",
    "recommended = [(name, round(output[i], 3)) \n",
    "               for i, name in enumerate(excipient_names) if output[i] > 0.01]\n",
    "\n",
    "recommended_sorted = sorted(recommended, key=lambda x: -x[1])[:5]\n",
    "print(\"推荐配方及用量：\")\n",
    "for name, dose in recommended_sorted:\n",
    "    print(f\"{name}: {dose}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6508a0-6fda-4251-868f-754d6894b443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
